{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "f8899015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree of OneAPI on Insurance Fraud Detection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "44a316e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py as d4p\n",
    "import numpy as np\n",
    "\n",
    "import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "4279add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv = pandas.read_csv(\"[Dataset]_Module11_(Insurance).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "8e8fdf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for col in read_csv.columns:\n",
    "    if col != 'fraud_reported':\n",
    "        features.append(col)\n",
    "\n",
    "target = 'fraud_reported'\n",
    "\n",
    "X = read_csv[features]\n",
    "y = read_csv[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "732292ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax: X_train, X_test, y_train, y_test = train_test_split()\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, prunedata, labels, prunelabels = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "b9baca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here,\n",
    "#X_train = data\n",
    "#y_train = labels\n",
    "#X_test = prunedata\n",
    "#y_test = prunelabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "0229afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_algo = d4p.decision_tree_classification_training(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "7092cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = train_algo.compute(data, labels, prunedata, prunelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "dfb8c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_algo = d4p.decision_tree_classification_prediction()\n",
    "\n",
    "predict_result = predict_algo.compute(prunedata, train_result.model)  #We pass X_test in predict_result (X_test = prunedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "1ad5fae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision tree prediction results (first 10 rows):\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Ground truth (first 10 rows):\n",
      " 507    0\n",
      "818    0\n",
      "452    0\n",
      "368    1\n",
      "242    0\n",
      "929    1\n",
      "262    1\n",
      "810    0\n",
      "318    0\n",
      "49     0\n",
      "Name: fraud_reported, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDecision tree prediction results (first 10 rows):\\n\", predict_result.prediction[0:10])\n",
    "print(\"\\nGround truth (first 10 rows):\\n\", prunelabels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "7f01f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "80c6ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = predict_result.prediction.reshape(-1) ##y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "825194a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prunelabels  #y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ddc9f49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[168,  12],\n",
       "       [ 11,  59]], dtype=int64)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "39553ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       180\n",
      "           1       0.83      0.84      0.84        70\n",
      "\n",
      "    accuracy                           0.91       250\n",
      "   macro avg       0.88      0.89      0.89       250\n",
      "weighted avg       0.91      0.91      0.91       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(b,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "c93d5f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN of OneAPI on Insurance Fraud Detection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "da0e1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py as d4p\n",
    "import numpy as np\n",
    "import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "e2528057",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv = pandas.read_csv(\"C:\\\\Users\\\\INDIA AI DATA LAB\\\\Downloads\\\\AIDA-Course\\\\AIDA-Course\\\\Module 11\\\\[Dataset]_Module11_(Insurance).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "7a9e95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for col in read_csv.columns:\n",
    "    if col != 'fraud_reported':\n",
    "        features.append(col)\n",
    "\n",
    "target = 'fraud_reported'\n",
    "\n",
    "X = read_csv[features]\n",
    "y = read_csv[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "2bc4bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax: X_train, X_test, y_train, y_test = train_test_split()\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, prunedata, labels, prunelabels = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "cf3966e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nFeatures = 2\n",
    "nClasses = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "1a8b458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_algo = d4p.kdtree_knn_classification_training(nClasses=nClasses)\n",
    "#weights = np.ones((data.shape[0], 1))\n",
    "train_result = train_algo.compute(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "9cf8f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_algo = d4p.kdtree_knn_classification_prediction(nClasses=nClasses)\n",
    "predict_result = predict_algo.compute(prunedata, train_result.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "94ab86f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN classification results:\n",
      "Ground truth(observations #13-14):\n",
      " 345    0\n",
      "971    0\n",
      "Name: fraud_reported, dtype: int64\n",
      "Classification results(observations #13-14):\n",
      " [[0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"kNN classification results:\")\n",
    "print(\"Ground truth(observations #13-14):\\n\", prunelabels[13:15])\n",
    "print(\"Classification results(observations #13-14):\\n\", predict_result.prediction[13:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "2fe92bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "#a = predict_result.prediction.reshape(-1)\n",
    "a = predict_result.prediction  #Here, result is same without reshape too, check how?\n",
    "b = prunelabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "d787ea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143,  37],\n",
       "       [ 60,  10]], dtype=int64)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "74af69aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.75       180\n",
      "           1       0.21      0.14      0.17        70\n",
      "\n",
      "    accuracy                           0.61       250\n",
      "   macro avg       0.46      0.47      0.46       250\n",
      "weighted avg       0.57      0.61      0.59       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(b,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "e68a6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision forest of OneAPI on Insurance Fraud Detection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "69b45944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py as d4p\n",
    "import numpy as np\n",
    "\n",
    "import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "30b989bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv = pandas.read_csv(\"C:\\\\Users\\\\INDIA AI DATA LAB\\\\Downloads\\\\AIDA-Course\\\\AIDA-Course\\\\Module 11\\\\[Dataset]_Module11_(Insurance).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "75ea130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for col in read_csv.columns:\n",
    "    if col != 'fraud_reported':\n",
    "        features.append(col)\n",
    "\n",
    "target = 'fraud_reported'\n",
    "\n",
    "X = read_csv[features]\n",
    "y = read_csv[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "353202e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax: X_train, X_test, y_train, y_test = train_test_split()\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, prunedata, labels, prunelabels = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "737557ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets configure a training object (5 classes)\n",
    "train_algo = d4p.decision_forest_classification_training(5,\n",
    "                                                         nTrees=10,\n",
    "                                                         minObservationsInLeafNode=8,\n",
    "                                                         featuresPerNode=3,\n",
    "                                                         engine = d4p.engines_mt19937(seed=777),\n",
    "                                                         varImportance='MDI',\n",
    "                                                         bootstrap=True,\n",
    "                                                         resultsToCompute='computeOutOfBagError')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "fb0c5133",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = train_algo.compute(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "f44eac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_algo = d4p.decision_forest_classification_prediction(nClasses=5)\n",
    "predict_result = predict_algo.compute(prunedata, train_result.model)\n",
    "assert(predict_result.prediction.shape == (prunedata.shape[0], 1))\n",
    "#We pass x_test(prunedata here) in predict_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "67cc25ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random forest prediction results (first 10 rows):\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Ground truth (first 10 rows):\n",
      " 507    0\n",
      "818    0\n",
      "452    0\n",
      "368    1\n",
      "242    0\n",
      "929    1\n",
      "262    1\n",
      "810    0\n",
      "318    0\n",
      "49     0\n",
      "Name: fraud_reported, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#And then we compare y_pred(predict_result.prediction here) with y_test(prunelabels here)\n",
    "print(\"\\nRandom forest prediction results (first 10 rows):\\n\", predict_result.prediction[0:10])\n",
    "print(\"\\nGround truth (first 10 rows):\\n\", prunelabels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "8aa49fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "a = predict_result.prediction.reshape(-1)\n",
    "b = prunelabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "69e2dad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[178,   2],\n",
       "       [ 59,  11]], dtype=int64)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "efbe8dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.85       180\n",
      "           1       0.85      0.16      0.27        70\n",
      "\n",
      "    accuracy                           0.76       250\n",
      "   macro avg       0.80      0.57      0.56       250\n",
      "weighted avg       0.78      0.76      0.69       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(b,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "79959fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM of OneAPI on Insurance fraud detection dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "88759ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py as d4p \n",
    "import numpy as np\n",
    "import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "3f40cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv = pandas.read_csv(\"C:\\\\Users\\\\INDIA AI DATA LAB\\\\Downloads\\\\AIDA-Course\\\\AIDA-Course\\\\Module 11\\\\[Dataset]_Module11_(Insurance).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "cdeba7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for i in read_csv.columns:\n",
    "    if i != 'fraud_reported':\n",
    "        features.append(i)\n",
    "\n",
    "target = 'fraud_reported'\n",
    "X = read_csv[features]\n",
    "y = read_csv[target]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "1cc1e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y==0] = -1    #Changing all 0 values to 1 as svm can only distinguish bw -1 and 1 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "d75f93d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud_reported\n",
       "-1    753\n",
       " 1    247\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "fbfbe13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data, prunedata, labels, prunelabels = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "7728c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_algo = d4p.svm_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "21046850",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = train_algo.compute(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "eff6a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_algo = d4p.svm_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "9f933e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result =predict_algo.compute(prunedata, train_result.model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "182e984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert(predict_result.prediction.shape == (prunedata.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "d3f6ad84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine prediction results (first 10 rows):\n",
      " [[-1.30911009]\n",
      " [-1.21683948]\n",
      " [-1.96909834]\n",
      " [-1.12062208]\n",
      " [-2.13948189]\n",
      " [-0.48394354]\n",
      " [ 0.91034205]\n",
      " [-1.81697164]\n",
      " [-0.07427428]\n",
      " [ 0.50070007]]\n",
      "\n",
      "Ground truth (first 10 rows):\n",
      " 507   -1\n",
      "818   -1\n",
      "452   -1\n",
      "368    1\n",
      "242   -1\n",
      "929    1\n",
      "262    1\n",
      "810   -1\n",
      "318   -1\n",
      "49    -1\n",
      "Name: fraud_reported, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSupport Vector Machine prediction results (first 10 rows):\\n\", predict_result.prediction[0:10])\n",
    "print(\"\\nGround truth (first 10 rows):\\n\", prunelabels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "0106a150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, -1]\n"
     ]
    }
   ],
   "source": [
    "#SVM can only distinguish between -1 and 1 results thus we coverted our negative values to -1 and positive values to 1\n",
    "a = predict_result.prediction.reshape(-1)\n",
    "b =[ -1 if v<0 else 1 for v in a]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "779a27a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine prediction results (first 10 rows):\n",
      " [-1, -1, -1, -1, -1, -1, 1, -1, -1, 1]\n",
      "\n",
      "Ground truth (first 10 rows):\n",
      " 507   -1\n",
      "818   -1\n",
      "452   -1\n",
      "368    1\n",
      "242   -1\n",
      "929    1\n",
      "262    1\n",
      "810   -1\n",
      "318   -1\n",
      "49    -1\n",
      "Name: fraud_reported, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSupport Vector Machine prediction results (first 10 rows):\\n\", b[0:10])  # b is y_pred(converted from predict_result.prediction)\n",
    "print(\"\\nGround truth (first 10 rows):\\n\", prunelabels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "b46d6df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "#a = predict_result.prediction.reshape(-1) \n",
    "c = prunelabels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "8ae24626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[140,  45],\n",
       "       [ 40,  25]], dtype=int64)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here, c is y_test and b is y_pred(converted in -1 and 1)\n",
    "confusion_matrix(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "0425d72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.76      0.77       185\n",
      "           1       0.36      0.38      0.37        65\n",
      "\n",
      "    accuracy                           0.66       250\n",
      "   macro avg       0.57      0.57      0.57       250\n",
      "weighted avg       0.67      0.66      0.66       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "93520d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes of OneAPI on Insurance fraud detection dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "d9cf6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py as d4p\n",
    "import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "8eeadd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv = pandas.read_csv(\"C:\\\\Users\\\\INDIA AI DATA LAB\\\\Downloads\\\\AIDA-Course\\\\AIDA-Course\\\\Module 11\\\\[Dataset]_Module11_(Insurance).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "caabb14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for col in read_csv.columns:\n",
    "    if col != 'target_reported':\n",
    "        features.append(col)\n",
    "target = 'fraud_reported'\n",
    "X = read_csv[features]\n",
    "y = read_csv[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "2a661382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax: X_train, X_test, y_train, y_test = train_test_split()\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, prunedata, labels, prunelabels = train_test_split(X,y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "e506ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_algo = d4p.multinomial_naive_bayes_training(2)\n",
    "train_result = train_algo.compute(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "d65f525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_algo = d4p.multinomial_naive_bayes_prediction(2)\n",
    "predict_result = predict_algo.compute(prunedata, train_result.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "c4aa7a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes prediction results (first 10 rows):\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Ground truth (first 10 rows):\n",
      " 507    0\n",
      "818    0\n",
      "452    0\n",
      "368    1\n",
      "242    0\n",
      "929    1\n",
      "262    1\n",
      "810    0\n",
      "318    0\n",
      "49     0\n",
      "Name: fraud_reported, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMultinomial Naive Bayes prediction results (first 10 rows):\\n\", predict_result.prediction[0:10])  \n",
    "print(\"\\nGround truth (first 10 rows):\\n\", prunelabels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "cd2a1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "a = predict_result.prediction #y_pred\n",
    "b = prunelabels #y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "c3b9905c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[180,   0],\n",
       "       [ 70,   0]], dtype=int64)"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "0af1c7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84       180\n",
      "           1       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.72       250\n",
      "   macro avg       0.36      0.50      0.42       250\n",
      "weighted avg       0.52      0.72      0.60       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDIA AI DATA LAB\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\INDIA AI DATA LAB\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\INDIA AI DATA LAB\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(b,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08905ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression of OneAPI on Insurance fraud detection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "42362f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py as d4p\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "442b607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv = pandas.read_csv(\"C:\\\\Users\\\\INDIA AI DATA LAB\\\\Downloads\\\\AIDA-Course\\\\AIDA-Course\\\\Module 11\\\\[Dataset]_Module11_(Insurance).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "5a555e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for col in read_csv:\n",
    "    if col != 'fraud_reported':\n",
    "        features.append(col)\n",
    "\n",
    "target = 'fraud_reported'\n",
    "\n",
    "X = read_csv[features]\n",
    "y = read_csv[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "84316093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data, prunedata, labels, prunelabels = train_test_split(X, y, random_state = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "03606351",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_algo = d4p.logistic_regression_training(2)\n",
    "train_result = train_algo.compute(data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "aaf437c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_algo = d4p.logistic_regression_prediction(2)\n",
    "predict_result = predict_algo.compute(prunedata, train_result.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "bc739db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression prediction results (first 10 rows):\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Ground truth (first 10 rows):\n",
      " 507    0\n",
      "818    0\n",
      "452    0\n",
      "368    1\n",
      "242    0\n",
      "929    1\n",
      "262    1\n",
      "810    0\n",
      "318    0\n",
      "49     0\n",
      "Name: fraud_reported, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLogistic Regression prediction results (first 10 rows):\\n\", predict_result.prediction[0:10])  \n",
    "print(\"\\nGround truth (first 10 rows):\\n\", prunelabels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "c3ecf899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "a = predict_result.prediction #y_pred\n",
    "b = prunelabels #y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "98191ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[167,  13],\n",
       "       [ 67,   3]], dtype=int64)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "83160982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.81       180\n",
      "           1       0.19      0.04      0.07        70\n",
      "\n",
      "    accuracy                           0.68       250\n",
      "   macro avg       0.45      0.49      0.44       250\n",
      "weighted avg       0.57      0.68      0.60       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(b,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "569b03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification algorithms used here and their accuracy:\n",
    "#1 Decision Tree = 91%\n",
    "#2 K-nearest neighbour = 61%\n",
    "#3 Decision Forest = 76%\n",
    "#4 SVM = 66%\n",
    "#5 Multinomial Naive Bayes = 72%\n",
    "#6 Logistic Regression = 68%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f955a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform all classification algorithms on Recommendation system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
